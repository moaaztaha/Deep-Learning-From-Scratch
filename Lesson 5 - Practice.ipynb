{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96958463, 0.77513282, 0.93949894, 0.89482735, 0.59789998],\n",
       "       [0.92187424, 0.0884925 , 0.19598286, 0.04522729, 0.32533033],\n",
       "       [0.38867729, 0.27134903, 0.82873751, 0.35675333, 0.28093451],\n",
       "       [0.54269608, 0.14092422, 0.80219698, 0.07455064, 0.98688694],\n",
       "       [0.77224477, 0.19871568, 0.00552212, 0.81546143, 0.70685734]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.rand(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_layer(input, d1, d2):\n",
    "    out = input @ np.random.rand(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((784, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9466, 1.7256, 1.2597,  ..., 1.3359, 1.9041, 1.7468],\n",
       "        [1.7700, 1.0561, 1.3516,  ..., 1.5009, 1.5269, 1.0142],\n",
       "        [1.1566, 1.5628, 1.2256,  ..., 1.6972, 1.1102, 1.6321],\n",
       "        ...,\n",
       "        [1.6929, 1.3285, 1.7769,  ..., 1.2916, 1.4130, 1.3615],\n",
       "        [1.6815, 1.2236, 1.2000,  ..., 1.4086, 1.5227, 1.6996],\n",
       "        [1.0361, 1.1655, 1.1084,  ..., 1.5562, 1.2067, 1.7014]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLinear(nn.Module):\n",
    "    def __init__(self, input, out, bias=True):\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.in_features = input\n",
    "        self.out_features = out\n",
    "        \n",
    "        self.w = torch.rand((input, out))\n",
    "        self.bias_vector = torch.ones(10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.bias:\n",
    "            return x @ self.w + self.bias_vector\n",
    "        return x @ self.w\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return f'in_features={self.in_features}, out_features={self.out_features}, bias={self.bias}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = myLinear(784, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myLinear(in_features=784, out_features=10, bias=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[198.6807, 192.7532, 194.0907, 194.1066, 191.0456, 193.8449, 193.0988,\n",
       "         186.3689, 192.9310, 193.1070]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = myLinear(784, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mnist_Logistic(\n",
       "  (linear): myLinear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myLinear(in_features=784, out_features=10, bias=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
